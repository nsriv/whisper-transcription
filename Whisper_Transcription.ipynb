{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsriv/whisper-transcription/blob/main/Whisper_Transcription.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j2OSfW1COy4"
      },
      "source": [
        "# Whisper AI Transcription"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About\n",
        "\n",
        "This Colab Notebook is designed to transcribe a given audio file, of any language, into text. To accomplish this, it uses the code contained in this notebook, which leverages open-source and free of cost Python packages and machine learning models. The transcription of the audio file is contained within the Google Drive account mounted in the section on \"Saving,\" and upon exit of the runtime, all uploaded data is permanently deleted, thus not compromising user or patient privacy.\n",
        "\n",
        "This notebook runs in a 'runtime environment' on a virtual machine hosted on the Google Cloud Platform. This runtime is temporary and destructible, but is connected to a GPU that provides the muscle for the computation. Once the runtime is disconnected, all data except the text output is deleted. No data is sent back to Google except for the resources and running time requested by the code being executed."
      ],
      "metadata": {
        "id": "z2XB5U6Uy4kG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup\n",
        "\n",
        "**Please read this code notebook in its entirety before intial run.**\n",
        "\n",
        "This will allow you to understand a few decisions made and empower you to modify them in the future.\n"
      ],
      "metadata": {
        "id": "vz-6oNOoxmoB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Runtime Connection\n",
        "\n",
        "From the top menu (File, Edit, etc...):\n",
        "\n",
        "* Select 'Runtime' > 'Change Runtime Type'\n",
        "\n",
        "* From the dropdown menu under 'Hardware Accelerator' select 'GPU'\n",
        "\n",
        "* Confirm by clicking 'Save'\n",
        "\n",
        "You should now see, on the right side of the screen below the \"Comment\" button, an orange indicator that will run through \"Allocating, Connecting, Initializing, Connected\" before turning green and showing a green checkmark while displaying RAM and Disk usage of our runtime.\n",
        "\n",
        "If you do not see this, or it says Reconnect, you should repeat the steps above and click Reconnect before proceeding. While it should connect the first time you run a code cell, it needs to know you want GPU connection, or else code execution will take an inordinately long time."
      ],
      "metadata": {
        "id": "KgAJJaMD2CIT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkNDWxgdERQG"
      },
      "source": [
        "# Installing Whisper (and some goodies)\n",
        "\n",
        "Commands below will install the Python packages necessary to run Whisper models.\n",
        "\n",
        "* Whisper.git will fetch the most up-to-date version of the [open-source Whisper package from OpenAI\n",
        "](https://github.com/openai/whisper)\n",
        "* [JiWER](https://github.com/jitsi/jiwer) is a package used to appoximate error rates for the model. It is not necessary in the code as is, but is included here for future reportage use.\n",
        "* ipython-autotime is an extension that will display the time of execution after each command is run.\n",
        "\n",
        "**Click the play button to run commands. It will turn into a running indicator/Stop button while code is executing and will turn into a green checkmark upon completion.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrUGR0axE8Ca",
        "outputId": "fb564fc3-9273-4559-804b-d6bf230e2304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-9p60mosj\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-9p60mosj\n",
            "  Resolved https://github.com/openai/whisper.git to commit 248b6cb124225dd263bb9bd32d060b6517e067f8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230314)\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798075 sha256=2ac630f5629179f3949d6d5aaea86ea1bc2a968242bd768c166ba2ea1867c173\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rmh5o5vw/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20230314 tiktoken-0.3.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.3)\n",
            "Collecting rapidfuzz==2.13.7 (from jiwer)\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.1 rapidfuzz-2.13.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.6)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.2\n",
            "time: 333 µs (started: 2023-05-30 15:55:44 +00:00)\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n",
        "! pip install jiwer\n",
        "! pip install ipython-autotime\n",
        "%load_ext autotime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvzfv_TfHABT"
      },
      "source": [
        "# Setting Up File Workspace: Saving\n",
        "\n",
        "Create a folder called \"Whisper\" in your Google Drive, then run the cell below to connect it to this code notebook.\n",
        "\n",
        "Upon running, you should see a \"Permissions\" popup asking you to select and connect the Google Drive account you would like to use to store your text output.\n",
        "\n",
        "This folder can be renamed later if necessary, but you'll need to change the path file in an upcoming line of code. (See Notes at the end)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4n62TGQHdot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f95e838d-04d5-4c8b-adb1-b3a9e0a43fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "time: 22 s (started: 2022-11-20 21:23:20 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrXf435YIYz0"
      },
      "source": [
        "# Setting up File Workspace: Upload\n",
        "\n",
        "To upload a file, notice that there is a folder icon in the toolbar to the left. Click it to open the left pane.\n",
        "\n",
        "1. Drag your audio file here. All common audio formats work: .m4a, .mp3, .wav, .flac, etc.\n",
        "2. Wait for it to fully upload. This can be finicky on a spotty connection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nktMUnvCJm1h"
      },
      "source": [
        "# Usage\n",
        "\n",
        "\n",
        "1. Once upload is complete, click on the three dots to the right of the filename and select \"Copy Path\"\n",
        "2. Paste the path in between the quotes in the cell below (\"/content/your_audio_file_here\") and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeDHCbncJGl1"
      },
      "outputs": [],
      "source": [
        "!whisper \"/content/your_audio_file_here\" --model medium --output_dir /content/drive/MyDrive/Whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGTcg6AUK-Nr"
      },
      "source": [
        "# Notes\n",
        "* By default, Whisper outputs 3 files of text per audio file input: a .txt file with no time stamps contained in it, and both an .srt and .vtt file which are repsectively a subtitles and video subtitles/closed-captioning file, which include timestamps and can be replayed using the free and open-source [VLC media player.](https://www.videolan.org/vlc/)\n",
        "\n",
        "* OpenAI's Whisper package has several sizes of model, tiny, base, small, medium, and large. Each one has a correspondingly large download time before audio analysis can begin, but yields greater accuracy. To balance these, I've used the flag \"--model medium.\"\n",
        "\n",
        "* If, as mentioned earlier, you wish to save the transcribed output into a different folder, simply change \"Whisper\" in the file path following \"--output_dir\" to the name of your chosen folder.\n",
        "\n",
        "* There is no specification in the above command of a flag for the language, so Whisper analyzes the first 30 seconds of audio to autodetect the language. If you want to very slightly speed up the process, you can give it a flag such as \"--Spanish.\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN9bXLFcoCdrfgbyDW7CwoD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}